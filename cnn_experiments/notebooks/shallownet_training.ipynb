{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15498fd1-7509-4f3d-a465-a31444830a60",
   "metadata": {},
   "source": [
    "# Training a ShallowNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a8ff3-97bd-4382-b151-0146655145f8",
   "metadata": {},
   "source": [
    "__Objective:__ train a ShallowNet CNN to classify image data.\n",
    "\n",
    "We experiment with:\n",
    "- Loading data into tensors.\n",
    "- Loading data into Tensorflow `Dataset`s.\n",
    "- Defining the model via Keras' `Sequential` API.\n",
    "- Defining the model as a Keras `Layer` object using the functional API and then putting it into a `Model` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1776e59-5042-4696-84b0-76c4685dcc02",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635bf55-e95a-4bde-9ab7-c44426927408",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_dir = '../data/Dataset/'\n",
    "test_data_dir = '../data/Dataset_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f38971-cb89-43a9-9063-d30665eb1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72daaa7-261b-40e0-a543-ece8376c95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_dir(dir_path, color_mode='grayscale', target_size=(32, 32)):\n",
    "    \"\"\"\n",
    "    Given the path to a directory containing images, loads the images\n",
    "    in a tensor using the provided `color_mode` and `target_size` options.\n",
    "    \"\"\"\n",
    "    image_tensors = tf.concat(\n",
    "        [\n",
    "            img_to_array(load_img(\n",
    "                os.path.join(dir_path, image_name),\n",
    "                color_mode=color_mode,\n",
    "                target_size=target_size,\n",
    "                keep_aspect_ratio=False if target_size is None else True\n",
    "            ))[tf.newaxis]\n",
    "            for image_name in os.listdir(dir_path)\n",
    "        ],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    return image_tensors\n",
    "\n",
    "\n",
    "def load_image_dataset(dataset_dir, color_mode='grayscale', target_size=(32, 32), shuffle=True):\n",
    "    \"\"\"\n",
    "    Loads a dataset of images for the given directory. The data directory is\n",
    "    assumed to be strctured in sub-directories, each named as a numeric class\n",
    "    label and containing all the images belonging to the corresponding class.\n",
    "    \"\"\"\n",
    "    classes = sorted([\n",
    "        int(c) for c in os.listdir(dataset_dir)\n",
    "        if c.isnumeric()\n",
    "    ])\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for c in classes:\n",
    "        x.append(load_images_from_dir(\n",
    "            os.path.join(dataset_dir, f'{c}/'),\n",
    "            color_mode=color_mode,\n",
    "            target_size=target_size\n",
    "        ))\n",
    "\n",
    "        y.append(c * tf.ones(shape=x[-1].shape[0]))\n",
    "\n",
    "    x = tf.concat(x, axis=0)\n",
    "    y = tf.concat(y, axis=0)\n",
    "\n",
    "    # Normalize pixel values.\n",
    "    pixel_normalization = tf.reduce_max(x)\n",
    "\n",
    "    x /= pixel_normalization\n",
    "\n",
    "    # Shuffle data if required.\n",
    "    if shuffle:\n",
    "        shuffled_indices = tf.random.shuffle(tf.range(x.shape[0]))\n",
    "\n",
    "        x = tf.gather(\n",
    "            x,\n",
    "            shuffled_indices,\n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        y = tf.gather(\n",
    "            y,\n",
    "            shuffled_indices,\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04451a-ca60-4658-a351-406c11415f41",
   "metadata": {},
   "source": [
    "Load training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d2d2e-8b22-4fd5-9c6c-81522634cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_image_dataset(training_data_dir)\n",
    "x_test, y_test = load_image_dataset(test_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02415db-676e-40cf-a0f0-653bf728343a",
   "metadata": {},
   "source": [
    "Print some random images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df289ab7-d800-420a-9348-e6ceae176c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = tf.random.uniform(shape=(3,), minval=0, maxval=x_train.shape[0], dtype=tf.int32)\n",
    "\n",
    "random_images = tf.gather(x_train, random_indices)\n",
    "random_images_classes = tf.gather(y_train, random_indices)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14, 6))\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    axs[i].imshow(random_images[i, ...].numpy(), cmap='gray')\n",
    "\n",
    "    plt.sca(axs[i])\n",
    "    plt.title(f'Class: {int(random_images_classes[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09941400-48ca-4356-a6c6-23e6708cfb6b",
   "metadata": {},
   "source": [
    "### Alternative data loading: Tensorflow `Dataset`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56bd0cf-a165-4c1e-aad4-8e956832a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42fbe9-1834-4076-bc10-e26ce07bf3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = image_dataset_from_directory(\n",
    "    training_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    image_size=(32, 32),\n",
    "    shuffle=True,\n",
    "    crop_to_aspect_ratio=True\n",
    ")\n",
    "\n",
    "# Normalize pixel values.\n",
    "training_dataset = training_dataset.map(\n",
    "    lambda x, y: (x / 255., y)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    image_size=(32, 32),\n",
    "    shuffle=True,\n",
    "    crop_to_aspect_ratio=True\n",
    ")\n",
    "\n",
    "# Normalize pixel values.\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda x, y: (x / 255., y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab9f1f-02dc-428f-a325-8940e9e570fe",
   "metadata": {},
   "source": [
    "## Define and train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d602ad3-997a-49bc-a187-4b7c130ec9f0",
   "metadata": {},
   "source": [
    "### Model definition via the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c68ae6-7bf5-4f8c-b287-a403a53ab083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a798177-645b-4517-a695-d4ed0c7cbd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(training_history, metrics=None):\n",
    "    \"\"\"\n",
    "    Plots loss and additional metrics (if any) across training\n",
    "    epochs. Additional metrics must be provided as a list of\n",
    "    strings.\n",
    "    \"\"\"\n",
    "    nrows = len(metrics) + 1 if metrics is not None else 1\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "    sns.lineplot(\n",
    "        x=range(len(training_history.history['loss'])),\n",
    "        y=training_history.history['loss'],\n",
    "        ax=axs[0],\n",
    "        label='Training'\n",
    "    )\n",
    "\n",
    "    if 'val_loss' in training_history.history.keys():\n",
    "        sns.lineplot(\n",
    "            x=range(len(training_history.history['val_loss'])),\n",
    "            y=training_history.history['val_loss'],\n",
    "            ax=axs[0],\n",
    "            label='Validation'\n",
    "        )\n",
    "        \n",
    "    plt.sca(axs[0])\n",
    "    plt.title('Loss')\n",
    "\n",
    "    if metrics is not None:\n",
    "        for i, metric in enumerate(metrics):\n",
    "            sns.lineplot(\n",
    "                x=range(len(training_history.history[metric])),\n",
    "                y=training_history.history[metric],\n",
    "                ax=axs[i + 1],\n",
    "                label='Training'\n",
    "            )\n",
    "        \n",
    "            if f'val_{metric}' in training_history.history.keys():\n",
    "                sns.lineplot(\n",
    "                    x=range(len(training_history.history[f'val_{metric}'])),\n",
    "                    y=training_history.history[f'val_{metric}'],\n",
    "                    ax=axs[i + 1],\n",
    "                    label='Validation'\n",
    "                )\n",
    "    \n",
    "            plt.sca(axs[i + 1])\n",
    "            plt.title(metric)\n",
    "\n",
    "    plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a304d-05eb-4034-8712-31aecbe33e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, n_classes):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "\n",
    "        input_shape = (height, width, depth)\n",
    "\n",
    "        model.add(Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same',\n",
    "            input_shape=input_shape\n",
    "        ))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=n_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa108ff-27f8-42b6-8634-6ab787270bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_model = ShallowNet().build(width=32, height=32, depth=1, n_classes=10)\n",
    "\n",
    "sn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0846636-3ba0-4ed2-979a-c7f41bb39bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_model(x_train[:1, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b8545-1f30-400a-b09a-0d4d0af469e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=5e-3)\n",
    "\n",
    "sn_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "training_history = sn_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3884ca4f-5761-4bb8-b3a1-bcc64bcef2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(training_history, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbbf88-6084-4eb1-875e-e3033d98a996",
   "metadata": {},
   "source": [
    "### Model definition via the functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe110ebe-67ce-409c-86f8-782d37c1c4fd",
   "metadata": {},
   "source": [
    "Build a model starting from Keras `Layer` and `Model` objects and using the functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0ec68-7a7a-4392-9ad7-08eeee7bd68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad2ef5-a1de-4daf-bb38-04bc8776cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNetLayer(Layer):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same'\n",
    "        )\n",
    "        self.relu = Activation('relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(units=n_classes)\n",
    "        self.softmax = Activation('softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        output = self.softmax(x)\n",
    "\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613513e3-5dba-4655-8075-985e7460d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_layer = ShallowNetLayer(n_classes=10)\n",
    "\n",
    "inputs = Input(shape=(32, 32, 1))\n",
    "outputs = sn_layer(inputs)\n",
    "\n",
    "sn_model_from_layer = Model(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs\n",
    ")\n",
    "\n",
    "optimizer_2 = tf.keras.optimizers.SGD(learning_rate=5e-3)\n",
    "\n",
    "sn_model_from_layer.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer_2,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Training with manually loaded data.\n",
    "# training_history_2 = sn_model_from_layer.fit(\n",
    "#     x_train,\n",
    "#     y_train,\n",
    "#     batch_size=32,\n",
    "#     epochs=100,\n",
    "#     validation_data=(x_test, y_test)\n",
    "# )\n",
    "\n",
    "# Training with Tensorflow Datasets.\n",
    "training_history_2 = sn_model_from_layer.fit(\n",
    "    training_dataset,\n",
    "    batch_size=None,\n",
    "    epochs=100,\n",
    "    validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6d419-ed7c-4e45-a656-7942bda23aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(training_history_2, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2b5ae-c5f9-43b8-a925-ed6dda80b00e",
   "metadata": {},
   "source": [
    "## Accessing a model's intermediate output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5115e8-1216-4b91-80be-8b5db52e6dda",
   "metadata": {},
   "source": [
    "Extract the intermediate output (from hidden layers) of a trained model by defining another model built from the trained model's layers.\n",
    "\n",
    "__Note:__ this is easily done with the sequential if we have a sequential model and we want to get its first N layers - more complicated models require the functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d6660-6b48-45f7-8638-353c791987db",
   "metadata": {},
   "source": [
    "Isolate the names of the trained model's layers (in order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47ed9f-2375-4f00-ab0f-fdabf1a10b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f938c34-6acb-4044-a8eb-43c7bc8965db",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extraction_layer_names = [layer['config']['name'] for layer in sn_model.get_config()['layers']][1:3]\n",
    "\n",
    "features_extraction_layer_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a3dd8-616f-4e34-9526-211308d9031e",
   "metadata": {},
   "source": [
    "Define a sequential model getting the list of layers of the original one by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112de4c4-5c77-4306-8aca-68e246cc06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_model = Sequential([\n",
    "    sn_model.get_layer(layer_name)\n",
    "    for layer_name in features_extraction_layer_names\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40384405-613a-48b9-ace7-6c64e2a7ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output = feature_extraction_model(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379b995-74e7-414b-8a74-6a35ca4f6b76",
   "metadata": {},
   "source": [
    "Check the intermediate output from the convolutional layer against the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f42ae1-d01d-4c2c-a064-914bf6d7e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=3, figsize=(14, 14))\n",
    "\n",
    "for row in range(axs.shape[0]):\n",
    "    for col in range(axs.shape[1]):\n",
    "        ax = axs[row, col]\n",
    "\n",
    "        # The first row contains the original image.\n",
    "        if row == 0:\n",
    "            ax.imshow(x_test[0, ...].numpy(), cmap='gray')\n",
    "\n",
    "            plt.sca(ax)\n",
    "            plt.title('Original image')\n",
    "\n",
    "            break\n",
    "\n",
    "        # The second row contains 3 channels of the\n",
    "        # intermediate output.\n",
    "        if row == 1:\n",
    "            ax.imshow(intermediate_output[0, ..., col].numpy(), cmap='gray')\n",
    "\n",
    "            plt.sca(ax)\n",
    "            plt.title(f'Intermediate output: channel {col}')\n",
    "\n",
    "\n",
    "        # The first row contains the original image.\n",
    "        if row == 2:\n",
    "            ax.imshow(tf.reduce_mean(intermediate_output[:1, ...], axis=-1)[0, ...].numpy(), cmap='gray')\n",
    "\n",
    "            plt.sca(ax)\n",
    "            plt.title('Intermediate output: average over all channels')\n",
    "\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
