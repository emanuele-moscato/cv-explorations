{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6a351c-192d-4b99-b8b0-d8a19b788dc3",
   "metadata": {},
   "source": [
    "# The convolution operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76bb4f6-41e9-41aa-a860-f21656abdf72",
   "metadata": {},
   "source": [
    "The convolution operation between a 2D tensor $I$ (image) and e 2D tensor $K$ (\"kernel\") is usually defined in deep learning libraries as the matrix $S$ with entries\n",
    "$$\n",
    "S_{ij} = \\sum_k \\sum_l K_{i+k, j+l}\\,I_{kl}\n",
    "$$\n",
    "\n",
    "__Note:__ technically the above is known as \"cross-correlation\", but the misnomer has stuck within the deep learning community (the proper \"convolution\" differing only by the signs in $K$'s indices, which are respectively $i-k$ and $j-l$ in the proper case).\n",
    "\n",
    "Because a the notion of a \"center position\" (pixel) for the kernel is needed, kernels are taken to have odd dimensions. Moreover, square kernels are usually used.\n",
    "\n",
    "Given an image matrix of size $N\\times M$ and a kernel of size $F\\times F$, the kernel has a \"frame\" around the center of size $(F-1)/2$ and the resulting output (if no padding is added back after the convolution operation and with unit stride) has size $(M-F+1)\\times (N-F+1)$ (each dimension is subtracted twice the size of the kernel's frame). $F$ is said to be the **kernel's receptive field**.\n",
    "\n",
    "Strides $S$ measures the step by which the center of the kernel is moved at each step across the image. $S=1$ correspond to the formula above, while for general (integer) values we have that $S - 1$ pixels are \"skipped\" at each step. In order for the kernel to perform a correct tiling of the image (covering all of it as it moves), the number of steps along all directions (starting at a corner, modulo the kernel's frame size) must be integer,\n",
    "$$\n",
    "\\frac{W - F}{S} + 1 \\in \\mathbb{N}\\,.\n",
    "$$\n",
    "\n",
    "__Note:__ the implementation of the convolution operation below is sequential and thus very inefficient. In fact, convolution is trivially parallelizable because the kernel acts of different patches of the image in a completely independent way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8beee3-a34e-43b8-9b81-b3b11d7fbaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778329ef-3c2b-47c6-922d-3f5da096df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, kernel, stride=1):\n",
    "    \"\"\"\n",
    "    Computes the convolution operation between an image\n",
    "    and a kernel. The image is assumed to be in grayscale\n",
    "    and the kernel is assumed to be square and with odd\n",
    "    receptive field (size). A non-unit stride can be used,\n",
    "    in which case a check on the feasibility of a complete\n",
    "    tiling of the image is performed (in the negative case,\n",
    "    an exception is raised).\n",
    "    \"\"\"\n",
    "    # Check that the kernel size is odd.\n",
    "    if kernel.shape[0] % 2 != 1:\n",
    "        raise Exception('Kernel size must be odd')\n",
    "    \n",
    "    # Size of the \"frame\" around the center of the kernel.\n",
    "    kernel_frame_size = int((kernel.shape[0] - 1) / 2)\n",
    "\n",
    "    # Check that the image shape is compatible with the\n",
    "    # kernel size and the stride.\n",
    "    n_steps_width = 1. + (image.shape[0] - 2. * kernel_frame_size - 1.) / stride\n",
    "    n_steps_height = 1. + (image.shape[1] - 2. * kernel_frame_size - 1.) / stride\n",
    "\n",
    "    if not n_steps_width.is_integer():\n",
    "        raise Exception('Image width, kernel receptive field and stride are incompatible')\n",
    "    if not n_steps_height.is_integer():\n",
    "        raise Exception('Image height, kernel receptive field and stride are incompatible')\n",
    "\n",
    "    # Dimension of the output tensor.\n",
    "    # output_dim = (\n",
    "    #     image.shape[0] - 2 * kernel_frame_size,\n",
    "    #     image.shape[1] - 2 * kernel_frame_size\n",
    "    # )\n",
    "    output_dim = (int(n_steps_width), int(n_steps_height))\n",
    "\n",
    "    # Initialize the output tensor.\n",
    "    output = tf.Variable(tf.zeros(shape=(output_dim[0], output_dim[1]), dtype=tf.float32))\n",
    "\n",
    "    # Compute the convolution.\n",
    "    # Loop over the rows of the image.\n",
    "    for i in tqdm(range(output_dim[0])):\n",
    "        # Loop over the columns of the image.\n",
    "        for j in range(output_dim[1]):\n",
    "            # Compute the coordinates of the center of the kernel.\n",
    "            kernel_center_coords = [i * stride + kernel_frame_size, j * stride + kernel_frame_size]\n",
    "\n",
    "            # Isolate the patch in the image overlapping with the kernel, given the\n",
    "            # position of its center on the image itself.\n",
    "            image_patch = image[\n",
    "                kernel_center_coords[0] - kernel_frame_size: kernel_center_coords[0] + kernel_frame_size + 1,\n",
    "                kernel_center_coords[1] - kernel_frame_size: kernel_center_coords[1] + kernel_frame_size + 1\n",
    "            ]\n",
    "\n",
    "            # Compute the element-by-element product of the image patch\n",
    "            # with the kernel and take the sum of all the entries: that's\n",
    "            # the (i, j) entry of the output tensor.\n",
    "            output[i, j].assign(tf.reduce_sum(image_patch * kernel))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609f297-e03b-4eab-8987-868fb5299f57",
   "metadata": {},
   "source": [
    "Load an image (\"big\" matrix) in grayscale (only one channel for each pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901c1eb-ce3c-4335-89a2-3b0181d6b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single grayscale image.\n",
    "test_image = tf.cast(\n",
    "    tf.random.uniform(minval=0, maxval=256, shape=(128, 128), dtype=tf.int32),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "test_image = tf.convert_to_tensor(tf.keras.utils.load_img(\n",
    "    '../data/x-wing.jpeg',\n",
    "    color_mode='grayscale',\n",
    "    target_size=(200, 200),\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=True\n",
    "), dtype=tf.float32)\n",
    "\n",
    "# Print the test image.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.imshow(\n",
    "    test_image.numpy().astype('uint8'),\n",
    "    cmap='gray'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af814d-6f31-4719-b769-53a8b201c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba06296f-8463-4f1f-a722-05babac12f92",
   "metadata": {},
   "source": [
    "Create kernels (\"small\" square matrices with odd size)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d025aa-8b71-4fc8-b6e2-0e2a952bfaf4",
   "metadata": {},
   "source": [
    "Blurring kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96743560-4d6d-4306-846b-3d2a876a3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 11\n",
    "\n",
    "# A kernel with all entries equal to 1/(kernel_size ** 2) should\n",
    "# correspond to a blurring kernel.\n",
    "blurring_kernel = tf.ones(shape=(kernel_size, kernel_size)) / (kernel_size ** 2)\n",
    "\n",
    "# Compute convolution with stride 1.\n",
    "print('Convolution with stride=1')\n",
    "\n",
    "test_output = convolve(test_image, blurring_kernel)\n",
    "\n",
    "# Print the resulting image.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.imshow(\n",
    "    test_output.numpy().astype('uint8'),\n",
    "    cmap='gray'\n",
    ")\n",
    "\n",
    "\n",
    "# Compute convolution with stride 3.\n",
    "print('Convolution with stride=3')\n",
    "\n",
    "test_output = convolve(test_image, blurring_kernel, stride=3)\n",
    "\n",
    "# Print the resulting image.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.imshow(\n",
    "    test_output.numpy().astype('uint8'),\n",
    "    cmap='gray'\n",
    ")\n",
    "\n",
    "\n",
    "# Compute convolution with stride 7.\n",
    "print('Convolution with stride=7')\n",
    "\n",
    "test_output = convolve(test_image, blurring_kernel, stride=7)\n",
    "\n",
    "# Print the resulting image.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.imshow(\n",
    "    test_output.numpy().astype('uint8'),\n",
    "    cmap='gray'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c592947-5818-4210-8eec-9d0129ab0bb7",
   "metadata": {},
   "source": [
    "Sharpening kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956513d-4ad6-4523-9b3b-0ced9a76e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpening_kernel = (\n",
    "    - tf.linalg.band_part(tf.ones(shape=(5, 5)), 1, 1)\n",
    "    + tf.linalg.tensor_diag([1., 1., 6., 1., 1.])\n",
    ")\n",
    "\n",
    "# Compute convolution with stride 1.\n",
    "print('Convolution with stride=1')\n",
    "\n",
    "sharpened_output = convolve(test_image, sharpening_kernel)\n",
    "\n",
    "# Print the resulting image.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.imshow(\n",
    "    sharpened_output.numpy().astype('uint8'),\n",
    "    cmap='gray'\n",
    ")\n",
    "\n",
    "\n",
    "# Compute convolution with stride 3.\n",
    "print('Convolution with stride=3')\n",
    "\n",
    "sharpened_output = convolve(test_image, sharpening_kernel, stride=3)\n",
    "\n",
    "# Print the resulting image.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.imshow(\n",
    "    sharpened_output.numpy().astype('uint8'),\n",
    "    cmap='gray'\n",
    ")\n",
    "\n",
    "\n",
    "# Compute convolution with stride 5.\n",
    "print('Convolution with stride=5')\n",
    "\n",
    "sharpened_output = convolve(test_image, sharpening_kernel, stride=5)\n",
    "\n",
    "# Print the resulting image.\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.imshow(\n",
    "    sharpened_output.numpy().astype('uint8'),\n",
    "    cmap='gray'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
